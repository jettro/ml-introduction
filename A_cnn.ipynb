{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs) for Image Classification\n",
    "In this notebook we will demonstrate how to build a Convolutional Neural Network (CNN) for image classification using the Keras library. We will use the MNIST dataset, which consists of 60,000 training images and 10,000 test images of handwritten digits (0-9). The goal is to train a model that can classify the images into their respective digit classes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import keras\n",
    "from keras import layers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting up the CNN architecture\n",
    "We define the following Convolutional Neural Network (CNN) architecture:\n",
    "- The input expects images of size 28x28 with a single color channel (typically greyscale images)\n",
    "- The first Convolution layer extracts local features like edges, corners, etc\n",
    "- The first pooling layer reduces the spatial dimensions of the image\n",
    "- The second and third  Convolution layer extracts higher-level features (more complex patterns)\n",
    "- A flattening layer converts the 2D matrix data to a vector for classification\n",
    "- A dense (fully connected) layer with 10 units, where each unit corresponds to a class in a 10-class classification problem (for example, digit classification from 0 to 9).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the model on the MNist dataset\n",
    "This code demonstrates how to load and preprocess the MNIST dataset, compile a model, and train it using Keras. The MNIST dataset consists of 60,000 training images and 10,000 test images, where each image is a 28x28 grayscale image of handwritten digits (0-9). Below is a breakdown of the code:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset. It contains 60,000 training images and 10,000 test images of handwritten digits (0-9)\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# The images are reshaped to have an extra dimension (1) for the color channel \n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# The pixel values are scaled from [0, 255] to the range of [0, 1]\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# Since this is a multi-class classification problem, the loss function used is sparse categorical crossentropy.\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# During training, the model optimizes its parameters (weights and biases) to minimize the loss function, \n",
    "# improving its performance on the task of classifying images.\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating the model on the test set"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
